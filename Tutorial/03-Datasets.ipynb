{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives\n",
    " * Use the h5pyd package to connect with the HDF Kita Server\n",
    " * Explore characterstics of Datasets\n",
    " * Look at different ways of reading/writing to datasets\n",
    " * Examine how chunking works with HDF Server\n",
    " * Tricks for best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_H5PY=1  # set to 0 to use HDF Server instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if USE_H5PY:\n",
    "    import h5py\n",
    "else:\n",
    "    import h5pyd as h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get folder/directory for HDF files we create  \n",
    "#\n",
    "def getMyFolder():\n",
    "    DIR_NAME = \"HDFLabTutorial/\"\n",
    "    if USE_H5PY:\n",
    "        myfolder = os.getenv(\"HOME\") + \"/\" + DIR_NAME\n",
    "        if not os.path.isdir(myfolder):\n",
    "            # create a directory on the local disk if needed\n",
    "            print(\"created folder:\", myfolder)\n",
    "            os.mkdir(myfolder)\n",
    "    else:\n",
    "        dir = h5py.Folder('/home/')  # get folder object for root\n",
    "        username = os.getenv(\"JUPYTERHUB_USER\")\n",
    "        myfolder = None\n",
    "        for name in dir:\n",
    "            # we should come across the given domain\n",
    "            if username.startswith(name):\n",
    "                # check any folders where the name matches at least part of the username\n",
    "                # e.g. folder: \"/home/bob/\" for username \"bob@acme.com\"\n",
    "                path = '/home/' + name + '/'\n",
    "                f = h5py.Folder(path)\n",
    "                if f.owner == username:\n",
    "                    myfolder = path\n",
    "                f.close()\n",
    "                if myfolder:\n",
    "                    break\n",
    "\n",
    "        dir.close()\n",
    "    \n",
    "        # create a workshop subfolder if not already present\n",
    "        myfolder += DIR_NAME\n",
    "        try:\n",
    "            h5py.Folder(myfolder)\n",
    "        except IOError as ioe:\n",
    "            if ioe.errno != 404:\n",
    "                return None  # unexpected error\n",
    "            # not present - create it now\n",
    "            h5py.Folder(myfolder, mode='x')\n",
    "            print(\"created folder:\", myfolder)\n",
    "       \n",
    "    return myfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/HDFLabTutorial/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get folder/directory for this tutorial\n",
    "home = getMyFolder()\n",
    "home  # this is the folder where you have permission to write to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a file/domain on the server\n",
    "domain_name = home + \"03.h5\"\n",
    "f = h5py.File(domain_name, 'w')\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The 'w' mode removes and existing file (if any) and creates a new empty file.\n",
    "Other modes supported are:\n",
    " * 'r': Open as read only, file must exist\n",
    " * 'r+': Read/write, file must exist\n",
    " * 'x': Create file, fail if exist\n",
    " * 'a': Read/write if exists, otherwise create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144115188075855872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The only object currently in the new file is the root group, we can get the id like this\n",
    "root = f['/']\n",
    "root.id.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"test1\": shape (3, 4), type \"<i8\">"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.create_dataset(\"test1\", (3,4), dtype='i8')  # we've created a dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now something shows up if we list the contents of the file\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset type is fixed at creation time\n",
    "dset = f['test1']\n",
    "dset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case the shape is fixed at create time, though we'll see later it is possible to\n",
    "# create extensible datasets\n",
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can read all the elements of a dataset using the ellipsis operator\n",
    "out = dset[...]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can update portions of the dataset using numpy-like syntax\n",
    "dset[0,0:4] = [1,2,3,4]\n",
    "dset[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only portions of the dataset that actually get written are stored\n",
    "# create a really big dataset\n",
    "f.create_dataset(\"big_data\", (1024,1024,1024), dtype='f4')  # 4 GB dataset!\n",
    "dset = f['big_data']\n",
    "dset[512,512,512] = 3.12  # write one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 3.12, 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back a small region\n",
    "dset[510:514,512,512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Use hsls -H -v with this file (or h5ls if for H5PY=1).  With hsls at first you may see no storage allocatted for the file, but this will update in a few seconds.\n",
    "h5ls will show the allocation immediately since everything is synchronous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset storage is broken up into \"chunks\".  Each chunk is stored as a seperate S3 object\n",
    "# unlike with h5py, datasets are always chunked (even if it is just one chunk!).\n",
    "# Chunks are determined automtically if not provided in the dataset create call\n",
    "dset.chunks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a chunk layout\n",
    "f.create_dataset(\"chunked_data\", (1024,1024,1024), dtype='f4',chunks=(1,1024,1024))\n",
    "dset = f[\"chunked_data\"]\n",
    "dset.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: The server will \"correct\" chunk layouts that result in chunks that are too small or too large.  Try creating datasets with very small and very large chunks.  What chunk layout do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big_data', 'chunked_data']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete a dataset by using the del operator.  Unlike with the HDF5 library, this doesn't leave\n",
    "# \"holes\" in the file.  Only storage that is actually allocated is used\n",
    "del f['test1']\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you would like a default value other than 0, specify a \n",
    "#   fill value when creating the dataset\n",
    "f.create_dataset(\"fill_value\", (1024,1024,1024), dtype='i4', fillvalue=42)\n",
    "dset = f['fill_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 42, 42], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[1,2,3:6]  # get 3 elements from the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Run h5ls/hsls -H -v with this file.  How many chunks in the dataset have been allocatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
